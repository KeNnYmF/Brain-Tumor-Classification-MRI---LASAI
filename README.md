# ğŸ§  ClasificaciÃ³n de Tumores Cerebrales (MRI) mediante Aprendizaje por Transferencia

## ğŸ“˜ Resumen del Proyecto

Este repositorio contiene el cÃ³digo fuente para un proyecto de **Deep Learning** enfocado en la **clasificaciÃ³n de imÃ¡genes de Resonancia MagnÃ©tica (MRI)** cerebrales.  
El objetivo es clasificar las imÃ¡genes en cuatro categorÃ­as distintas:

- `glioma_tumor`
- `meningioma_tumor`
- `pituitary_tumor`
- `no_tumor` (tejido cerebral sano)

El proyecto implementa un pipeline completo que abarca desde el **preprocesamiento de datos** hasta el **entrenamiento de una CNN (Red Neuronal Convolucional)** y su **despliegue en una aplicaciÃ³n web (Flask)**.

Este trabajo se inspira en la aplicaciÃ³n industrial de la Inteligencia Artificial en el radiodiagnÃ³stico, sirviendo como **prueba de concepto** para un sistema de asistencia al diagnÃ³stico mÃ©dico.

---

## ğŸ“Š Dataset

El proyecto utiliza el dataset pÃºblico **[Brain Tumor Classification (MRI)](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri/data)** de Kaggle.

La estructura se divide en dos conjuntos: **Training** y **Testing**.

### Datos de Entrenamiento (`Training/`)
- glioma_tumor: 826 archivos  
- meningioma_tumor: 822 archivos  
- no_tumor: 395 archivos  
- pituitary_tumor: 827 archivos  

### Datos de Prueba (`Testing/`)
- glioma_tumor: 100 archivos  
- meningioma_tumor: 115 archivos  
- no_tumor: 105 archivos  
- pituitary_tumor: 74 archivos  

> ğŸ”¸ Se identificÃ³ un **desbalance de clases** en el conjunto de entrenamiento: la clase `no_tumor` (395) es una minorÃ­a significativa frente a las clases tumorales (~820).

---

## ğŸ§¬ MetodologÃ­a

Para abordar la complejidad y similitud visual entre las clases, se implementÃ³ una estrategia de **Aprendizaje por Transferencia (Transfer Learning)** con **Ajuste Fino (Fine-Tuning)**.

---

## ğŸ—ï¸ Modelo Base: VGG16

El modelo **VGG16**, preentrenado en **ImageNet**, se usÃ³ como *backbone* para la extracciÃ³n de caracterÃ­sticas.  
Sobre esta base se construyÃ³ un nuevo clasificador con las siguientes capas:

- `GlobalAveragePooling2D`
- `Dropout` (para regularizaciÃ³n)
- `Dense` con activaciÃ³n `softmax` (4 clases de salida)

---

## âš™ï¸ Estrategia de Entrenamiento en Dos Fases

1. **Fase 1 â€“ Entrenamiento del Clasificador (Head):**  
   Se congelaron todas las capas del backbone (VGG16).  
   Solo se entrenÃ³ el clasificador con tasa de aprendizaje estÃ¡ndar (`1e-3`).

2. **Fase 2 â€“ Ajuste Fino (Fine-Tuning):**  
   Se descongelÃ³ el Ãºltimo bloque convolucional (`block5_conv1` en adelante).  
   El modelo se recompilÃ³ con tasa de aprendizaje baja (`1e-5`).

En ambas fases se usÃ³ **EarlyStopping** monitorizando `val_loss` para restaurar los mejores pesos y prevenir sobreajuste.

---

## âš–ï¸ GestiÃ³n de Desbalance de Clases

Para compensar el desbalance, se aplicÃ³ **ponderaciÃ³n de clases** (`class weights`) calculada con `sklearn.utils.compute_class_weight`.  
Esto penaliza mÃ¡s los errores en la clase minoritaria (`no_tumor`), equilibrando el aprendizaje.

---

## ğŸ” Aumento de Datos (Data Augmentation)

Se aplicÃ³ una capa de aumento robusta al inicio del pipeline:

- `RandomFlip` (horizontal)  
- `RandomRotation` (Â±20%)  
- `RandomZoom` (Â±20%)  
- `RandomContrast` (Â±20%)  
- `RandomBrightness` (Â±20%)  

Estas transformaciones mejoran la **generalizaciÃ³n** y reducen la **confusiÃ³n entre clases visualmente similares**.

---

## ğŸ“ˆ Resultados y EvaluaciÃ³n

El modelo final se evaluÃ³ sobre el conjunto de **Testing (394 imÃ¡genes)**.

### Historial de Entrenamiento
![Curvas de Entrenamiento](training_metrics_plot_final.png)

**Figura 1.** Curvas de precisiÃ³n y pÃ©rdida durante el entrenamiento.  

La lÃ­nea roja marca el inicio del *Fine-Tuning*, donde se observa una mejora notable en la precisiÃ³n de validaciÃ³n y una disminuciÃ³n constante de la pÃ©rdida.  

Las curvas paralelas confirman que el sobreajuste fue gestionado adecuadamente.

---
## ğŸ§© Matriz de ConfusiÃ³n

![Matriz de ConfusiÃ³n](confusion_matrix_final.png)

**Figura 2.** Matriz de ConfusiÃ³n sobre el conjunto de prueba.

La matriz de confusiÃ³n (Figura 2) visualiza los resultados del reporte.  
Se observan valores altos en la diagonal para **meningioma_tumor (111)**, **no_tumor (99)** y **pituitary_tumor (67)**.

Confirma el desafÃ­o de la clase **glioma_tumor**: de 100 casos verdaderos (fila *glioma_tumor*), el modelo solo predijo **39 correctamente**, mientras que confundiÃ³ **35 con *meningioma_tumor*** y **23 con *no_tumor***.  
Esta confusiÃ³n inter-clase es la principal limitaciÃ³n del modelo actual y el factor que reduce la precisiÃ³n global.

---
## ğŸ“ Estructura del Repositorio

```bash
.
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ Training/
â”‚   â””â”€â”€ Testing/
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ brain_tumor_vgg16_final.keras
â”œâ”€â”€ app.py                 # Servidor web 
â”œâ”€â”€ train.py               # Script para entrenar el modelo
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â”œâ”€â”€ classification_report_final.txt
â”œâ”€â”€ confusion_matrix_final.png
â””â”€â”€ training_metrics_plot_final.png
```

## âš™ï¸ InstalaciÃ³n

Clone este repositorio:

```bash
git clone https://github.com/TU_USUARIO/TU_REPOSITORIO.git
cd TU_REPOSITORIO
```
Clone este repositorio:
```bash
pip install -r requirements.txt
```
Descargue el dataset de Kaggle y colÃ³quelo dentro de la carpeta dataset/ siguiendo la estructura mostrada.

1ï¸âƒ£ Entrenar el Modelo

Para entrenar el modelo desde cero, ejecute el script train.py.
Este proceso (re)generarÃ¡ el archivo del modelo (brain_tumor_vgg16_final.keras) y todos los reportes de mÃ©tricas (.png y .txt).

```bash
python train.py
```

2ï¸âƒ£ Ejecutar la AplicaciÃ³n Web

Una vez que el modelo (brain_tumor_vgg16_final.keras) exista, inicie el servidor Flask:

```bash
python app.py
```
Abra su navegador web y vaya a:

ğŸ‘‰ http://127.0.0.1:5000/

AllÃ­ podrÃ¡ cargar una imagen MRI y recibir una predicciÃ³n automÃ¡tica.
