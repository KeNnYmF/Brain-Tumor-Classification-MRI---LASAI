# üß† Clasificaci√≥n de Tumores Cerebrales (MRI) mediante Aprendizaje por Transferencia

## üìò Resumen del Proyecto

Este repositorio contiene el c√≥digo fuente para un proyecto de **Deep Learning** enfocado en la **clasificaci√≥n de im√°genes de Resonancia Magn√©tica (MRI)** cerebrales.  
El objetivo es clasificar las im√°genes en cuatro categor√≠as distintas:

- `glioma_tumor`
- `meningioma_tumor`
- `pituitary_tumor`
- `no_tumor` (tejido cerebral sano)

El proyecto implementa un pipeline completo que abarca desde el **preprocesamiento de datos** hasta el **entrenamiento de una CNN (Red Neuronal Convolucional)** y su **despliegue en una aplicaci√≥n web (Flask)**.

Este trabajo se inspira en la aplicaci√≥n industrial de la Inteligencia Artificial en el radiodiagn√≥stico, sirviendo como **prueba de concepto** para un sistema de asistencia al diagn√≥stico m√©dico.

---

## üìä Dataset

El proyecto utiliza el dataset p√∫blico **[Brain Tumor Classification (MRI)](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri/data)** de Kaggle.

La estructura se divide en dos conjuntos: **Training** y **Testing**.

### Datos de Entrenamiento (`Training/`)
- glioma_tumor: 826 archivos  
- meningioma_tumor: 822 archivos  
- no_tumor: 395 archivos  
- pituitary_tumor: 827 archivos  

### Datos de Prueba (`Testing/`)
- glioma_tumor: 100 archivos  
- meningioma_tumor: 115 archivos  
- no_tumor: 105 archivos  
- pituitary_tumor: 74 archivos  

> üî∏ Se identific√≥ un **desbalance de clases** en el conjunto de entrenamiento: la clase `no_tumor` (395) es una minor√≠a significativa frente a las clases tumorales (~820).

---

## üß¨ Metodolog√≠a

Para abordar la complejidad y similitud visual entre las clases, se implement√≥ una estrategia de **Aprendizaje por Transferencia (Transfer Learning)** con **Ajuste Fino (Fine-Tuning)**.

---

## üèóÔ∏è Modelo Base: VGG16

El modelo **VGG16**, preentrenado en **ImageNet**, se us√≥ como *backbone* para la extracci√≥n de caracter√≠sticas.  
Sobre esta base se construy√≥ un nuevo clasificador con las siguientes capas:

- `GlobalAveragePooling2D`
- `Dropout` (para regularizaci√≥n)
- `Dense` con activaci√≥n `softmax` (4 clases de salida)

---

## ‚öôÔ∏è Estrategia de Entrenamiento en Dos Fases

1. **Fase 1 ‚Äì Entrenamiento del Clasificador (Head):**  
   Se congelaron todas las capas del backbone (VGG16).  
   Solo se entren√≥ el clasificador con tasa de aprendizaje est√°ndar (`1e-3`).

2. **Fase 2 ‚Äì Ajuste Fino (Fine-Tuning):**  
   Se descongel√≥ el √∫ltimo bloque convolucional (`block5_conv1` en adelante).  
   El modelo se recompil√≥ con tasa de aprendizaje baja (`1e-5`).

En ambas fases se us√≥ **EarlyStopping** monitorizando `val_loss` para restaurar los mejores pesos y prevenir sobreajuste.

---

## ‚öñÔ∏è Gesti√≥n de Desbalance de Clases

Para compensar el desbalance, se aplic√≥ **ponderaci√≥n de clases** (`class weights`) calculada con `sklearn.utils.compute_class_weight`.  
Esto penaliza m√°s los errores en la clase minoritaria (`no_tumor`), equilibrando el aprendizaje.

---

## üîÅ Aumento de Datos (Data Augmentation)

Se aplic√≥ una capa de aumento robusta al inicio del pipeline:

- `RandomFlip` (horizontal)  
- `RandomRotation` (¬±20%)  
- `RandomZoom` (¬±20%)  
- `RandomContrast` (¬±20%)  
- `RandomBrightness` (¬±20%)  

Estas transformaciones mejoran la **generalizaci√≥n** y reducen la **confusi√≥n entre clases visualmente similares**.

---

## üìà Resultados y Evaluaci√≥n

El modelo final se evalu√≥ sobre el conjunto de **Testing (394 im√°genes)**.

### Historial de Entrenamiento
![Curvas de Entrenamiento](training_metrics_plot_final.png)

**Figura 1.** Curvas de precisi√≥n y p√©rdida durante el entrenamiento.  

La l√≠nea roja marca el inicio del *Fine-Tuning*, donde se observa una mejora notable en la precisi√≥n de validaci√≥n y una disminuci√≥n constante de la p√©rdida.  

Las curvas paralelas confirman que el sobreajuste fue gestionado adecuadamente.

---
## üß© Matriz de Confusi√≥n

![Matriz de Confusi√≥n](confusion_matrix_final.png)

**Figura 2.** Matriz de Confusi√≥n sobre el conjunto de prueba.

La matriz de confusi√≥n (Figura 2) visualiza los resultados del reporte.  
Se observan valores altos en la diagonal para **meningioma_tumor (111)**, **no_tumor (99)** y **pituitary_tumor (67)**.

Confirma el desaf√≠o de la clase **glioma_tumor**: de 100 casos verdaderos (fila *glioma_tumor*), el modelo solo predijo **39 correctamente**, mientras que confundi√≥ **35 con *meningioma_tumor*** y **23 con *no_tumor***.  
Esta confusi√≥n inter-clase es la principal limitaci√≥n del modelo actual y el factor que reduce la precisi√≥n global.

---

## ‚öôÔ∏è Instalaci√≥n

Clone este repositorio:

```bash
git clone https://github.com/TU_USUARIO/TU_REPOSITORIO.git
cd TU_REPOSITORIO
```
Clone este repositorio:
```bash
pip install -r requirements.txt
```
Descargue el dataset de Kaggle y col√≥quelo dentro de la carpeta dataset/ siguiendo la estructura mostrada.

1Ô∏è‚É£ Entrenar el Modelo

Para entrenar el modelo desde cero, ejecute el script train.py.
Este proceso (re)generar√° el archivo del modelo (brain_tumor_vgg16_final.keras) y todos los reportes de m√©tricas (.png y .txt).

```bash
python train.py
```

2Ô∏è‚É£ Ejecutar la Aplicaci√≥n Web

Una vez que el modelo (brain_tumor_vgg16_final.keras) exista, inicie el servidor Flask:

```bash
python app.py
```
Abra su navegador web y vaya a:

üëâ http://127.0.0.1:5000/

All√≠ podr√° cargar una imagen MRI y recibir una predicci√≥n autom√°tica.
